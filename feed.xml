<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.1.6">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2017-07-14T01:38:31-07:00</updated><id>/</id><title>Kyle Lo</title><subtitle>Statistics and stuff</subtitle><author><name>Kyle Lo</name><email>kyleclo@uw.edu</email></author><entry><title>Maximum likelihood in TensorFlow pt. 1</title><link href="/maximum-likelihood-in-tensorflow-pt-1/" rel="alternate" type="text/html" title="Maximum likelihood in TensorFlow pt. 1" /><published>2017-05-08T00:00:00-07:00</published><updated>2017-05-08T00:00:00-07:00</updated><id>/maximum-likelihood-in-tensorflow-pt-1</id><content type="html" xml:base="/maximum-likelihood-in-tensorflow-pt-1/">&lt;p&gt;Here are step-by-step examples demonstrating how to use TensorFlow’s autodifferentiation toolbox for maximum likelihood estimation.  I show how to compute the MLEs of a univariate Gaussian using TensorFlow-provided gradient descent optimizers or by passing scipy’s BFGS optimizer to the TensorFlow computation graph.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#mle-of-univariate-gaussian-with-gradient-descent&quot;&gt;MLE of univariate Gaussian with gradient descent&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#preprocessing-the-data&quot;&gt;Preprocessing the data&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#part1&quot;&gt;Part 1: Define computational graph&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#part2&quot;&gt;Part 2:  Run optimization scheme&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#results&quot;&gt;Results&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#mle-of-univariate-gaussian-with-newton-methods&quot;&gt;MLE of univariate Gaussian with Newton methods&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#computing-the-hessian&quot;&gt;Computing the Hessian&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#convexity-of-natural-parameterization&quot;&gt;Convexity of natural parameterization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#using-scipys-bfgs-optimizer&quot;&gt;Using scipy’s BFGS optimizer&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#appendix&quot;&gt;Appendix&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#verify-gradient-and-hessian-computations&quot;&gt;Verify gradient and Hessian computations&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#gradient-descent-with-natural-parameters&quot;&gt;Gradient descent with natural parameters&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The full code for each of these examples can be found in &lt;a href=&quot;https://github.com/kyleclo/tensorflow-mle&quot;&gt;this repo&lt;/a&gt;.  The code snippets in this post are simplified for illustrative purposes, while the full code in the linked repo are executable.&lt;/p&gt;

&lt;h2 id=&quot;mle-of-univariate-gaussian-with-gradient-descent&quot;&gt;MLE of univariate Gaussian with gradient descent&lt;/h2&gt;

&lt;p&gt;Let’s start with a simple example using gradient descent to find the MLE of a univariate Gaussian variable $X$ with mean $\mu$ and standard deviation $\sigma$.  We observe an iid sample of size $n = 100$.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;TRUE_MU&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TRUE_SIGMA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SAMPLE_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRUE_MU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRUE_SIGMA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SAMPLE_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We know that the correct MLEs are the sample mean and sample standard deviation of the data.  We will be evaluating whether TensorFlow’s optimizer converges to these values.&lt;/p&gt;

&lt;h4 id=&quot;preprocessing-the-data&quot;&gt;Preprocessing the data&lt;/h4&gt;

&lt;p&gt;Before doing any optimization, let’s standardize the raw data.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;CENTER&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SCALE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CENTER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SCALE&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Standardizing variables can make it easier to set reasonable defaults for initial values and learning rate.  Usually, &lt;code class=&quot;highlighter-rouge&quot;&gt;CENTER = x_obs.mean()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;SCALE = x_obs.std()&lt;/code&gt;.  For our example, we instead standardize the data using its min and max values just so things aren’t too easy.&lt;/p&gt;

&lt;p&gt;Since the transformation is linear and the parameters of interest are the mean and standard deviation, the MLEs computed from the standardized data can be transformed back to get the MLEs of the original data:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\widehat{\mu}_{original} = SCALE \cdot \widehat{\mu}_{standard} + CENTER&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\widehat{\sigma}_{original} = SCALE \cdot \widehat{\sigma}_{standard}&lt;/script&gt;

&lt;p&gt;Note that we won’t always know how a specific transformation applied to the data will impact the parameters of interest.&lt;/p&gt;

&lt;p&gt;&lt;a id=&quot;part1&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;part-1--define-computational-graph&quot;&gt;Part 1:  Define computational graph&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tf&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# data&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;INIT_MU_PARAMS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;loc&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;scale&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;INIT_PHI_PARAMS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;loc&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;scale&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;RANDOM_SEED&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# params&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RANDOM_SEED&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INIT_MU_PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INIT_PHI_PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# loss&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gaussian_dist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distributions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;log_prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gaussian_dist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;neg_log_likelihood&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# gradient&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_log_likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Several things to note:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.contrib.distributions&lt;/code&gt; module provides implementations of common distributions, but its use is optional.  You can always simply define the loss function from scratch.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TensorFlow doesn’t seem to provide a way to explicitly enforce variable constraints, i.e. $\sigma \gt 0$.  To handle this, we use the parameterization $\sigma = \phi^2$:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;This means our loss function will be optimized with respect to $\phi \in \mathbb{R}$, and we won’t have awkward gradient steps that push $\sigma$ outside the range of viable values.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;But this also means the solution is non-unique: Two values of $\phi$ correspond to a single optimal $\sigma$.  The loss function is symmetric around $\phi = 0$, and we might be concerned with potential jumping between solutions if the true $\sigma$ is very small (causing the optimal $\phi$ values to be sufficiently close to each other in parameter space).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;For more discussion on this, see the section about variance-covariance parameterization using the Cholesky decomposition in &lt;a href=&quot;https://pdfs.semanticscholar.org/2ff5/5b99d6d94d331670719bb1df1827b4d502a7.pdf&quot;&gt;Pinheiro, J. C., &amp;amp; Bates, D. M. (1996)&lt;/a&gt;.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It’s common practice to randomly initialize parameters by drawing from independent zero-centered Gaussians.  One consideration is initializing $\phi$ to be sufficiently far from $0$ so our gradient doesn’t explode (see in &lt;a href=&quot;#verify-gradient-and-hessian-computations&quot;&gt;Appendix&lt;/a&gt; that gradient magnitude is inversely proportional to $\phi$).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Personally, I like using numpy’s &lt;code class=&quot;highlighter-rouge&quot;&gt;np.random.normal()&lt;/code&gt; rather than TensorFlow’s &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.random_normal()&lt;/code&gt; because I can check the generated value without using &lt;code class=&quot;highlighter-rouge&quot;&gt;sess.run()&lt;/code&gt;.  But the TensorFlow-provided function can be used with a GPU, so for those interested:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;INIT_MU_PARAMS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;stddev&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;INIT_PHI_PARAMS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;stddev&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
                                                &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RANDOM_SEED&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INIT_MU_PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
                                                 &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RANDOM_SEED&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                 &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INIT_PHI_PARAMS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a id=&quot;part2&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;part-2--run-optimization-scheme&quot;&gt;Part 2:  Run optimization scheme&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;MAX_ITER&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TOL_PARAM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TOL_LOSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TOL_GRAD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdamOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_op&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_log_likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;# initialize&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;obs_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;obs_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_log_likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;obs_grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# gradient step&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_op&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

        &lt;span class=&quot;c&quot;&gt;# update parameters&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;new_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;diff_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subtract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                                               &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]))&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# update loss&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;new_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_log_likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss_diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c&quot;&gt;# update gradient&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;new_grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grad_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;obs_mu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;obs_phi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;obs_sigma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;obs_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;obs_grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_diff_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TOL_PARAM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Parameter convergence in {} iterations!&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TOL_LOSS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Loss function convergence in {} iterations!&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TOL_GRAD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Gradient convergence in {} iterations!&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_ITER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Max number of iterations reached without convergence.&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;More notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;We used the Adam optimizer which is a pretty good default choice since it has a momentum-based adaptive step size.  I’ve noticed that traversing steep or flat regions of parameter space can be problematic since the Adam update rule depends on an averaging of past computed gradients.  You can see this effect by changing the $\phi$ initialization closer to $0$ which causes the gradient to explode.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;See &lt;a href=&quot;http://sebastianruder.com/optimizing-gradient-descent/&quot;&gt;Sebastian Ruder’s blog post&lt;/a&gt; for an overview of other (stochastic) gradient descent methods, though I think time is better spent worrying about improving the initialization scheme.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The initial learning rate at $\alpha = 0.001$ and convergence tolerance values at $\delta = 10^{-8}$ are common default choices.  Standardizing the variables can make it easier to set reasonable defaults that work across multiple realizations of the generating distribution, but picking good values for $\alpha$ and $\delta$ is often a trial-and-error effort.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;When checking for parameter convergence, the norm of the parameter vector is computed using the values of $\phi$ even though we choose to display values of $\sigma$ for interpretability.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;results&quot;&gt;Results&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  iter |     mu     |   sigma    |    loss    |    grad   
     1 | 0.17740524 | 1.07955348 | 107.118011 | 166.314087
   101 | 0.27897912 | 0.87825149 | 86.2192841 | 185.379456
   201 | 0.38198292 | 0.68829656 | 61.8442612 | 208.598816
   301 | 0.47547418 | 0.51341331 | 34.3445473 | 229.603500
   401 | 0.53297198 | 0.36388707 | 7.32367325 | 222.097382
   501 | 0.54181617 | 0.25903416 | -10.640480 | 137.181747
   601 | 0.54176593 | 0.21581791 | -14.554010 | 26.8282032
   701 | 0.54176593 | 0.20935123 | -14.655022 | 1.52713740

Loss function convergence in 718 iterations!

Fitted MLE: [0.5418, 0.2092]
Target MLE: [0.5418, 0.2090]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The optimization procedure indeed converges (within some floating point precision) to the sample mean and sample standard deviation of the transformed data — it works!  The full code for this example is provided &lt;a href=&quot;https://github.com/kyleclo/tensorflow-mle/blob/master/univariate_gauss_adam.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/canon-adam-001.png&quot; alt=&quot;canon-adam-001&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;mle-of-univariate-gaussian-with-newton-methods&quot;&gt;MLE of univariate Gaussian with Newton methods&lt;/h2&gt;

&lt;p&gt;What about Newton methods?  Even if most optimization problems are non-convex, I seems like a good idea to know how to call BFGS in TensorFlow.&lt;/p&gt;

&lt;h4 id=&quot;computing-the-hessian&quot;&gt;Computing the Hessian&lt;/h4&gt;

&lt;p&gt;TensorFlow provides a &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.hessians()&lt;/code&gt; function that appears similar to &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.gradients()&lt;/code&gt; in its API, but I’ve found it extremely difficult to work with — grumble grumble can only compute second derivatives with respect to one-dimensional Tensors.&lt;/p&gt;

&lt;p&gt;Instead, I recommend something like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;grad[0]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;grad[1]&lt;/code&gt; are the derivatives of &lt;code class=&quot;highlighter-rouge&quot;&gt;neg_log_likelihood&lt;/code&gt; with respect to &lt;code class=&quot;highlighter-rouge&quot;&gt;mu&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;phi&lt;/code&gt; respectively.&lt;/p&gt;

&lt;p&gt;For example, the final Hessian upon convergence is:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;| 2285.12793 | -0.0032801 |
| -0.0032043 | 3814.80054 |
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;which we can verify is positive definite by checking:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;np.linalg.cholesky(obs_hess[-1])&lt;/code&gt; successfully returns a result, or&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;np.linalg.eigvals(obs_hess[-1])&lt;/code&gt; returns all positive eigenvalues&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;obs_hess&lt;/code&gt; is a list storing the computed Hessians at each iteration.&lt;/p&gt;

&lt;h4 id=&quot;convexity-of-natural-parameterization&quot;&gt;Convexity of natural parameterization&lt;/h4&gt;

&lt;p&gt;Note that the computed Hessians are not always positive definite.  For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;obs_hess[0]&lt;/code&gt; is:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;| 85.8048019 | 120.359650 |
| 120.359650 | -45.029373 |
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;While we can &lt;a href=&quot;https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter8.pdf&quot;&gt;prove&lt;/a&gt; that the natural parameter space for exponential families is always convex, this is not necessarily true for other parameterizations.&lt;/p&gt;

&lt;p&gt;The distributions provided by &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.contrib.distributions&lt;/code&gt; don’t have natural parameterization options, so they’ll need to be coded from scratch.  Let’s do this for the Gaussian distribution:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{\eta}(x) = h(x) \exp\left( \eta \cdot T(x) - A(\eta) \right)&lt;/script&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The natural parameters $\eta =\left[\mu / 2 \sigma^2, -1 / 2 \sigma^2 \right]^T$&lt;/li&gt;
  &lt;li&gt;The sufficient statistics $T(x) = \left[ x, x^2 \right]^T$&lt;/li&gt;
  &lt;li&gt;The log-partition function $A(\eta) = -\eta_1^2/ 4 \eta_2 - \log (-2\eta_2) / 2$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dropping the constant term $h(x)$, we replace our loss function with:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;log_partition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;log_prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_partition&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;neg_log_likelihood&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;eta1&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;eta2&lt;/code&gt; are our defined parameters instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;mu&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;phi&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;using-scipys-bfgs-optimizer&quot;&gt;Using scipy’s BFGS optimizer&lt;/h4&gt;

&lt;p&gt;Now that we have a convex loss function, we can use a Newton method for faster convergence.  TensorFlow provides an interface for external optimizers.  For example, we can use scipy’s BFGS optimizer:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ScipyOptimizerInterface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_log_likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                   &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;L-BFGS-B&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Note the API is slightly different.  We’re passing in the session into the optimizer’s &lt;code class=&quot;highlighter-rouge&quot;&gt;minimize()&lt;/code&gt; method instead of calling &lt;code class=&quot;highlighter-rouge&quot;&gt;sess.run()&lt;/code&gt;.   The full code for this example is provided &lt;a href=&quot;https://github.com/kyleclo/tensorflow-mle/blob/master/univariate_gauss_bfgs.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Running it, we see the algorithm converges very quickly to the solution:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  iter |     mu     |   sigma    |    loss    |    grad   
     1 | 0.54175494 | 0.20899648 | -106.54919 | 0.00128950

Parameter convergence in 3 iterations!

Fitted MLE: [0.5418, 0.2090]
Target MLE: [0.5418, 0.2090]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Don’t be confused by the output.  The optimization is taking gradients and hessians with respect to the natural parameters.  I simply like reporting $\mu$ and $\sigma$ because they’re more interpretable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/bfgs-musigma.png&quot; alt=&quot;bfgs-musigma&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/bfgs-eta.png&quot; alt=&quot;bfgs-eta&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;

&lt;h4 id=&quot;verify-gradient-and-hessian-computations&quot;&gt;Verify gradient and Hessian computations&lt;/h4&gt;

&lt;p&gt;Let’s quickly verify that our code for computing gradients and Hessians are correct.  We derive analytically:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}(\mu, \phi) = n \log \phi^2 + \frac{\sum (x_i - \mu)^2}{2\phi^4}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\nabla \mathcal{L}(\mu, \phi) = \begin{pmatrix} - \frac{\sum(x_i - \mu)}{\phi^4} &amp; \frac{2n}{\phi} - \frac{2\sum(x_i - \mu)^2}{\phi^5} \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\text{Hess } \mathcal{L}(\mu, \phi) = \begin{pmatrix}
\frac{n}{\phi^4} &amp; \frac{4 \sum(x_i - \mu)}{\phi^5} \\ \frac{4\sum(x_i - \mu)}{\phi^5} &amp; -\frac{2n}{\phi^2} + \frac{10 \sum (x_i - \mu)^2}{\phi^6}
\end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now we can evaluate:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;analytic_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;analytic_hess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;h11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;h21&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;h12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h21&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;h22&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;analytic_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;analytic_hess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;which match the values of &lt;code class=&quot;highlighter-rouge&quot;&gt;obs_grad[-1]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;obs_hess[-1]&lt;/code&gt; (up to some floating point precision).&lt;/p&gt;

&lt;h4 id=&quot;gradient-descent-with-natural-parameters&quot;&gt;Gradient descent with natural parameters&lt;/h4&gt;

&lt;p&gt;We performed gradient descent on the canonical parameters and BFGS on the natural parameters.  But is there any benefit to performing gradient descent on the natural parameters?&lt;/p&gt;

&lt;p&gt;Maybe.&lt;/p&gt;

&lt;p&gt;To illustrate, let’s run Adam on the natural parameters (see the commented-out lines in BFGS example code) with initial learning rate $\alpha = 0.1$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/nat-adam-01-musigma.png&quot; alt=&quot;nat-adam-01-musigma&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/nat-adam-01-eta.png&quot; alt=&quot;nat-adam-01-eta&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And we compare this to running Adam on the canonical parameters also with $\alpha = 0.1$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/canon-adam-01.png&quot; alt=&quot;canon-adam-01&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For this choice of $\alpha$, we notice:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The natural parameterization converges slower than the canonical parameterization.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The natural parameterization seems to result in a smoothly-decreasing loss function whereas the loss under the canonical parameterization appears unstable.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The gradient path under natural parameterization is a straight shot towards the location of the optima whereas the gradient path under canonical parameterization traverses parameter space in a more roundabout way.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And these empirical observations seem to hold for different choices of $\alpha$, though I still don’t really have a great explanation for why.&lt;/p&gt;

&lt;h4 id=&quot;resources&quot;&gt;Resources&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v28/sutskever13.pdf&quot;&gt;Sutskever, I., Martens, J., Dahl, G., &amp;amp; Hinton, G. (2013, February). On the importance of initialization and momentum in deep learning. In International conference on machine learning (pp. 1139-1147).&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pdfs.semanticscholar.org/2ff5/5b99d6d94d331670719bb1df1827b4d502a7.pdf&quot;&gt;Pinheiro, J. C., &amp;amp; Bates, D. M. (1996). Unconstrained parametrizations for variance-covariance matrices. Statistics and Computing, 6(3), 289-296.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1609.04747.pdf&quot;&gt;Ruder, S. (2016). An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.&lt;/a&gt;&lt;/p&gt;</content><author><name>Kyle Lo</name><email>kyleclo@uw.edu</email></author><summary>Here are step-by-step examples demonstrating how to use TensorFlow’s autodifferentiation toolbox for maximum likelihood estimation.  I show how to compute the MLEs of a univariate Gaussian using TensorFlow-provided gradient descent optimizers or by passing scipy’s BFGS optimizer to the TensorFlow computation graph.</summary></entry><entry><title>Deriving the backpropagation algorithm</title><link href="/deriving-the-backpropagation-algorithm/" rel="alternate" type="text/html" title="Deriving the backpropagation algorithm" /><published>2016-12-28T00:00:00-08:00</published><updated>2016-12-28T00:00:00-08:00</updated><id>/deriving-the-backpropagation-algorithm</id><content type="html" xml:base="/deriving-the-backpropagation-algorithm/">&lt;p&gt;Here are some notes containing step-by-step derivations of the backpropagation algorithm for neural networks.  This post serves more as a reference than as an introduction to the subject.  It assumes the reader is already familiar with neural networks and is comfortable with differentiation and matrix algebra.&lt;/p&gt;

&lt;p&gt;Regarding notation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;All vectors are column vectors unless otherwise specified.&lt;/li&gt;
  &lt;li&gt;The notation $g(x)$ for scalar function $g: \mathbb{R} \to \mathbb{R}$ and vector or matrix $x$ means the function is being applied element-wise.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;logistic-regression&quot;&gt;Logistic regression&lt;/h1&gt;

&lt;h3 id=&quot;setup&quot;&gt;Setup&lt;/h3&gt;

&lt;p&gt;We observe data $(y_1, x_1), \dots, (y_n, x_n)$ where $y_i \in {0, 1}$ and $x_i$ are vectors of length $m$.&lt;/p&gt;

&lt;p&gt;We assume the model $y \sim$ Bernoulli$\left(p(x) \right)$ where the mean response is $p(x) = \phi(w^T x)$.&lt;/p&gt;

&lt;p&gt;$\phi(z) = \frac{1}{1 + e^{-z}}$ is the expit (aka logistic) function.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;loss-function&quot;&gt;Loss function&lt;/h3&gt;

&lt;p&gt;We estimate $w$ using the maximum likelihood approach.  In other words, our goal is to minimize the negative log-likelihood loss (aka cross-entropy loss):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\mathcal{L}(w) &amp;= - \log \prod_{i=1}^n p(x_i)^{y_i} (1 - p(x_i))^{1-y_i}  \\
&amp;= - \sum_{i=1}^n \left[ y_i \log p(x_i) + (1 - y_i) \log (1 - p(x_i)) \right] \\
&amp;= - \sum_{i=1}^n \left[ y_i \log \phi(w^T x_i) + (1 - y_i) \log \left(1 - \phi(w^T x_i) \right) \right] 
\end{align} %]]&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;differentiation&quot;&gt;Differentiation&lt;/h3&gt;

&lt;p&gt;The derivative of the expit function is $\phi’(z) = \phi(z) \left(1 - \phi(z)\right)$.&lt;/p&gt;

&lt;p&gt;Then by chain rule, we derive the derivative of $\mathcal{L}(w)$ with respect to $w$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\partial \mathcal{L}(w)}{\partial w} &amp;= \sum_{i=1}^n \frac{\partial \mathcal{L}_i}{\partial \phi(w^T x_i)} \frac{\partial \phi(w^T x_i)}{\partial w^T x_i} \frac{\partial w^T x_i}{\partial w} \\
&amp;= -\sum_{i=1}^n  \left[ \frac{y_i}{\phi(w^T x_i)} + \frac{1 - y_i}{1 - \phi(w^T x_i)} \right] \phi(w^T x_i) \left(1 - \phi(w^T x_i) \right) x_i \\
&amp;= - \sum_{i=1}^n \left[y_i \left( 1 - \phi(w^T x_i) \right) - (1 - y_i) \phi(w^T x_i)  \right] x_i \\
&amp;= - \sum_{i=1}^n \left[ y_i - \phi(w^T x_i)   \right] x_i \\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;which is a vector of length $m$.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;softmax-regression&quot;&gt;Softmax regression&lt;/h1&gt;

&lt;p&gt;We think of our binary response as representing an observation’s membership in one of two classes.  With this in mind, we now generalize the logistic regression problem to handle $K$ classes.&lt;/p&gt;

&lt;h3 id=&quot;setup-1&quot;&gt;Setup&lt;/h3&gt;

&lt;p&gt;Our response $y$ indicates membership in one of $K$ classes.  We’ll use a one-hot encoding for the response, meaning each $y$ is a vector of length $K$.  For example, $y = [1, 0, \dots, 0]^T$ denotes membership in the first class.&lt;/p&gt;

&lt;p&gt;Statistically, we assume $y \sim$ Categorical$\left(p_1(x), \dots, p_K(x)\right)$ where the mean response is $p(x) = \left[p_1(x), \dots, p_K(x)\right]^T = \phi(w^T x)$.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Now $w$ is an $m \times K$ matrix instead of a vector.&lt;/p&gt;

&lt;p&gt;And $\phi$ is now the softmax function which takes input vector $z = [z_1, \dots, z_d]^T$ and outputs vector:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\phi(z) = \begin{pmatrix} e^{z_1} / \sum_j e^{z_j} \\ \vdots \\ e^{z_d} / \sum_j e^{z_j} \end{pmatrix}&lt;/script&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;loss-function-1&quot;&gt;Loss function&lt;/h3&gt;

&lt;p&gt;We’re still minimizing negative log-likelihood loss:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\mathcal{L}(w) &amp;= -\sum_{i=1}^n y_i^T \log p(x_i) \\
&amp;= -\sum_{i=1}^n y_i^T \log \phi(w^T x_i) 
\end{align} %]]&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;differentiation-a-idsoftmax-regression-differentiationa&quot;&gt;Differentiation &lt;a id=&quot;softmax-regression-differentiation&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;To keep things simple, let’s do this derivation for a single observation (hence, dropping the summation and index $i$ for now).  Our simplified loss function is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}(w) = -y^T \log \phi(w^T x)&lt;/script&gt;

&lt;p&gt;Also, let’s establish some shorthand notation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\phi = \phi(z)$ is the output vector, and $\phi_k$ denotes its $k^{th}$ element&lt;/li&gt;
  &lt;li&gt;$z = w^T x$ is the input vector to $\phi$, and $z_k$ denotes its $k^{th}$ element&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then by chain rule:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \mathcal{L}(w)}{\partial w} = \frac{\partial \mathcal{L}}{\partial \phi} \frac{\partial \phi}{\partial z} \frac{\partial z}{\partial w}&lt;/script&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\frac{\partial \mathcal{L}}{\partial \phi}$ is a row vector of length $K$:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\left(-y \odot \frac{1}{\phi}\right)^T = \begin{pmatrix} -\frac{y_1}{\phi_1} &amp; -\frac{y_2}{\phi_2} &amp; \dots &amp; -\frac{y_K}{\phi_K} \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$\frac{\partial \phi}{\partial z}$ is a $K \times K$ matrix (see Appendix for deriving the &lt;a href=&quot;#derivative-of-the-softmax-function&quot;&gt;derivative of the softmax function&lt;/a&gt;):&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{pmatrix} \phi_1 (1 - \phi_1) &amp; -\phi_1 \phi_2 &amp; \dots &amp; - \phi_1 \phi_K \\ 
- \phi_2 \phi_1 &amp; \phi_2 (1-\phi_2) &amp; \dots &amp; - \phi_2 \phi_K \\ 
\vdots  &amp; \vdots &amp; \ddots &amp; \vdots \\ 
-\phi_K \phi_1 &amp; -\phi_K \phi_2 &amp; \dots &amp; \phi_K (1-\phi_K) \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$\frac{\partial z}{\partial w}$ is a $K \times m \times K$ tensor.  See Appendix for &lt;a href=&quot;#deriving-the-tensor-for-softmax-regression&quot;&gt;derivation&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Multiplication of the first two terms gives a row vector of length $K$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\partial \mathcal{L}}{\partial \phi}  \frac{\partial \phi}{\partial z}&amp;= \begin{pmatrix} - y_1 (1-\phi_1) + \sum_{k \neq 1} y_k \phi_1 &amp;  \dots &amp; - y_K (1-\phi_K) + \sum_{k \neq K} y_k \phi_K \end{pmatrix} \\
&amp;= \begin{pmatrix} - y_1 + \phi_1 \sum_{k=1}^K y_k  &amp;  \dots &amp; - y_K + \phi_K \sum_{k=1}^K y_k  \end{pmatrix} \\
&amp;= \begin{pmatrix} \phi_1 - y_1  &amp; \dots &amp; \phi_K - y_K \end{pmatrix} \\ 
&amp;= \left[\phi(w^T x) - y\right]^T
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Then multiplying the resulting row vector with the tensor term gives an $m \times K$ matrix:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\partial \mathcal{L}}{\partial \phi} \frac{\partial \phi}{\partial z} \frac{\partial z}{\partial w} &amp;= \left[\phi(w^T x) - y\right]^T \left[ \frac{\partial w^T x}{\partial w}\right] \\
&amp;= x \left[\phi(w^T x) - y\right]^T
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;It turns out the tensor multiplication works out to this simple form.  See Appendix for &lt;a href=&quot;#showing-steps-in-vector-tensor-multiplication&quot;&gt;details&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Finally, putting everything back in terms of $n$ observations, we have the derivative of $\mathcal{L}(w)$ with respect to $w$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \mathcal{L}(w)}{\partial w} = -\sum_{i=1}^n x_i \left[y_i - \phi(w^T x_i) \right]^T&lt;/script&gt;

&lt;p&gt;which is an $m \times K$ matrix.&lt;/p&gt;

&lt;p&gt;This looks very similar to the derivative in the logistic regression setting (which is honestly kind of anti-climactic after all that work).  In fact, softmax regression for $K = 2$ is equivalent to logistic regression.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;neural-network&quot;&gt;Neural network&lt;/h1&gt;

&lt;h3 id=&quot;setup-2&quot;&gt;Setup&lt;/h3&gt;

&lt;p&gt;The neural network framework still assumes $y \sim$ Categorical$\left(p_1(x), \dots, p_K(x)\right)$ but now with a recursively-defined mean response:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\left[p_1(x), \dots, p_K(x)\right]^T = h^{(L)} &amp;= \phi_L \left(z^{(L)} \right) \\
h^{(L-1)} &amp;= \phi_{L-1}\left(z^{(L-1)} \right) \\
&amp;\vdots \\
h^{(1)} &amp;= \phi_1\left(z^{(1)} \right) \\
h^{(0)} &amp;= x 
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $z^{(l)} = w_l^T h^{(l-1)}$ for $l = 1,\dots,L$.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$h^{(0)}, \dots, h^{(L)}$ are vectors of length $m_l$ representing the collection of nodes at layer $l = 0, \dots, L$.  Notably, layers $0$ and $L$ are referred to as the input and output layers, respectively.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\phi_1, \dots, \phi_L$ are activation functions that map from $\mathbb{R}^{m_l}$ to $\mathbb{R}^{m_l}$.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;$\phi_L$ is typically the softmax function since we want $h^{(L)}$ entries, like probabilities, to sum to $1$.  Hence, when $L = 1$, a neural network with the softmax activation for its output layer is equivalent to softmax regression.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$\phi_1,\dots,\phi_{L-1}$ are often instead characterized by a nonlinear scalar function (e.g. expit, $\tanh$, ReLU) applied element-wise to input vectors.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$w_1, \dots, w_L$ are $m_{l-1} \times m_l$ parameter matrices.  Notably, $w_1$ has dimensions $m \times m_1$ to match the input vector $x$, and $w_L$ has dimensions $m_{L-1} \times K$ to match the response $y$.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;loss-function-2&quot;&gt;Loss function&lt;/h3&gt;

&lt;p&gt;Our goal is still to minimize the negative log-likelihood loss:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}(w_{1:L}) = - \sum_{i=1}^n y_i^T \log h_i^{(L)}&lt;/script&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;differentiation-1&quot;&gt;Differentiation&lt;/h3&gt;

&lt;p&gt;As it turns out, differentiation for neural networks looks similar to differentiation for softmax regression.&lt;/p&gt;

&lt;p&gt;For simplicity, let’s again assume a single observation, so the loss function is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}(w_{1:L}) = - y^T \log h^{(L)}&lt;/script&gt;

&lt;p&gt;Then:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} \frac{\partial \mathcal{L}(w_{1:L})}{\partial w_L} &amp;= \underbrace{\frac{\partial \mathcal{L}}{\partial h^{(L)}} \frac{\partial h^{(L)}}{\partial z^{(L)}}}_{\delta^{(L)}} \frac{\partial z^{(L)}}{\partial w_L} \\
\frac{\partial \mathcal{L}(w_{1:L})}{\partial w_{L-1}} &amp;= \underbrace{\frac{\partial \mathcal{L}}{\partial h^{(L)}} \frac{\partial h^{(L)}}{\partial z^{(L)}} \frac{\partial z^{(L)}}{\partial h^{(L-1)}} \frac{\partial h^{(L-1)}}{\partial z^{(L-1)}}}_{\delta^{(L-1)}} \frac{\partial z^{(L-1)}}{\partial w_{L-1}} \\ 
&amp;\vdots \\
\frac{\partial \mathcal{L}(w_{1:L})}{\partial w_1} &amp;= \underbrace{\frac{\partial \mathcal{L}}{\partial h^{(L)}}  \frac{\partial h^{(L)}}{\partial z^{(L)}} \left[ \prod_{l=2}^L \frac{\partial z^{(l)}}{\partial h^{(l-1)}}  \frac{\partial h^{(l-1)}}{\partial z^{(l-1)}} \right]}_{\delta^{(1)}}  \frac{\partial z^{(1)}}{\partial w_1}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\frac{\partial \mathcal{L}}{\partial h^{(L)}}$ is a row vector of length $K$:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\left(-y \odot \frac{1}{h^{(L)}}\right)^T = \begin{pmatrix} -\frac{y_1}{h^{(L)}_1} &amp; -\frac{y_2}{h^{(L)}_2} &amp; \dots &amp; -\frac{y_K}{h^{(L)}_K} \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$\frac{\partial h^{(l)}}{\partial z^{(l)}}$ are $m_l \times m_l$ matrices (i.e. derivative of activation function $\phi_l$ with respect to input vector $z^{(l)}$).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\frac{\partial z^{(l)}}{\partial h^{(l-1)}} = \frac{\partial w_l^T h^{(l-1)}}{\partial h^{(l-1)}} = w_l^T$ are $m_l \times m_{l-1}$ matrices.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\frac{\partial z^{(l)}}{\partial w_l}$ is an $m_l \times m_{l-1} \times m_l$ tensor (with same form as $\frac{\partial z}{\partial w}$ for softmax regression with $h_j^{(l-1)}$ replacing the $x_j$ elements).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;for $l = 1, \dots, L$.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Notice that $\delta^{(l)} = \frac{\partial \mathcal{L}}{\partial z^{(l)}} = \frac{\partial \mathcal{L}}{\partial h^{(L)}}  \frac{\partial h^{(L)}}{\partial z^{(L)}} \cdots  \frac{\partial h^{(l)}}{\partial z^{(l)}} $ is a row vector, and $\frac{\partial z^{(l)}}{\partial w_l}$ is a tensor of a familiar form.  Then using what we learned from softmax regression:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta^{(l)}\frac{\partial z^{(l)}}{\partial w_l} = h^{(l-1)} \delta^{(l)}&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Finally, returning to $n$ observations, the derivative of $\mathcal{L}(w_{1:L})$ with respect to $w_l$ is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \mathcal{L}(w_{1:L})}{\partial w_l} = \sum_{i=1}^n h_i^{(l-1)} \delta_i^{(l)}&lt;/script&gt;

&lt;p&gt;for $l = 1,\dots,L$.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;backpropagation&quot;&gt;Backpropagation&lt;/h3&gt;

&lt;p&gt;The backpropagation algorithm is simply an efficient way for computing the derivatives by noticing that $\delta^{(l)}$ terms can be reused between layers:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Compute $h_i^{(1)}, \dots, h_i^{(L)}$ for $i = 1,\dots,n$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Initialize $\delta_i = \frac{\partial \mathcal{L}_i}{\partial h_i^{(L)}}\frac{\partial h_i^{(L)}}{\partial z_i^{(L)}}$ for $i = 1,\dots,n$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For $l = L$ down to $1$:&lt;/p&gt;

    &lt;p&gt;a. Compute $\frac{\partial \mathcal{L}(w_{1:L})}{\partial w_l} = \sum_{i=1}^n h_i^{(l-1)} \delta_i$.&lt;/p&gt;

    &lt;p&gt;b. Update $\delta_i \gets \delta_i \frac{\partial z^{(l)}}{\partial h^{(l-1)}} \frac{\partial h_i^{(l-1)}}{\partial z_i^{(l-1)}}$ for $i = 1,\dots,n$.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The $\delta^{(l)}$ computations comprise most of the heavy-lifting since: $\frac{\partial h^{(l)}}{\partial z^{(l)}} = \phi’(z^{(l)})$ and $\frac{\partial z^{(l)}}{\partial h^{(l-1)}} = w_l^T$ can be large matrices.  There’s not much we can do about the latter term, but see the &lt;a href=&quot;#faster-computation-of-delta-terms&quot;&gt;Appendix&lt;/a&gt; for ways to speed up multiplication involving the former term.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;appendix&quot;&gt;Appendix&lt;/h1&gt;

&lt;h3 id=&quot;derivative-of-the-softmax-function&quot;&gt;Derivative of the softmax function&lt;/h3&gt;

&lt;p&gt;Since the softmax function is $\phi: \mathbb{R}^d \to \mathbb{R}^d$,  its derivative is a Jacobian matrix:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\phi&#39;(z) = \begin{pmatrix}
\frac{\partial \phi(z)_1}{z_1} &amp; \frac{\partial \phi(z)_1}{z_2} &amp; \dots &amp; \frac{\partial \phi(z)_1}{z_d} \\
\frac{\partial \phi(z)_2}{z_1} &amp; \frac{\partial \phi(z)_2}{z_2} &amp; \dots &amp; \frac{\partial \phi(z)_2}{z_d} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial \phi(z)_d}{z_1} &amp; \frac{\partial \phi(z)_d}{z_2} &amp; \dots &amp; \frac{\partial \phi(z)_d}{z_d} \\
\end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;Let’s derive each entry in this matrix.  We’ll index the rows by $i$ and columns by $j$.&lt;/p&gt;

&lt;p&gt;For $i = j$ entries, by quotient rule:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\partial \phi(z)_i}{\partial z_i} &amp;= \frac{e^{z_i} \sum_k e^{z_k} - e^{z_i} e^{z_i}}{ \sum_k e^{z_k} \sum_k e^{z_k} } \\
&amp;= \frac{e^{z_i}}{\sum_k e^{z_k}} \left(1 - \frac{e^{z_i}}{\sum_k e^{z_k}} \right)\\
&amp;= \phi(z)_i \left( 1 - \phi(z)_i \right)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;And for $i \neq j$ entries, by quotient rule:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\partial \phi(z)_i}{\partial z_j} &amp;= \frac{0 \sum_k e^{z_k} - e^{z_i} e^{z_j}}{ \sum_k e^{z_k} \sum_k e^{z_k} } \\
&amp;= - \frac{e^{z_i}}{\sum_k e^{z_k}} \frac{e^{z_j}}{\sum_k e^{z_k}} \\
&amp;= - \phi(z)_i \phi(z)_j
\end{align} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;deriving-the-tensor-for-softmax-regression&quot;&gt;Deriving the tensor for softmax regression&lt;/h3&gt;

&lt;p&gt;This section pertains to deriving the form of the tensor mentioned in &lt;a href=&quot;#softmax-regression-differentiation&quot;&gt;this section&lt;/a&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial z}{\partial w} = \frac{\partial w^T x}{\partial w} = 
\begin{pmatrix} 
\frac{\partial (w^T x)_1}{\partial w} \\ \frac{\partial (w^T x)_2}{\partial w} \\ \dots \\ \frac{\partial (w^T x)_K}{\partial w} 
\end{pmatrix}&lt;/script&gt;

&lt;p&gt;is a rank-3 tensor of dimension $K \times m \times K$ where:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\partial (w^T x)_1 }{\partial w} &amp;= \begin{pmatrix}\frac{\partial \sum w_{j1} x_j}{\partial w_{11}} &amp; \frac{\partial \sum w_{j1} x_j}{\partial w_{12}} &amp; \dots &amp; \frac{\partial \sum w_{j1} x_j}{\partial w_{1K}} \\ \frac{\partial \sum w_{j1} x_j}{\partial w_{21}} &amp; \frac{\partial \sum w_{j1} x_j}{\partial w_{22}} &amp; \dots &amp; \frac{\partial \sum w_{j1} x_j}{\partial w_{2K}} \\ \vdots &amp; \vdots &amp; \ddots \vdots \\ \frac{\partial \sum w_{j1} x_j}{\partial w_{m1}} &amp; \frac{\partial \sum w_{j1} x_j}{\partial w_{m2}} &amp; \dots &amp; \frac{\partial \sum w_{j1} x_j}{\partial w_{mK}} \end{pmatrix} \\
&amp;= \begin{pmatrix} x_1 &amp; 0 &amp; \dots &amp; 0 \\ x_2 &amp; 0 &amp; \dots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_m &amp; 0 &amp; \dots &amp; 0 \end{pmatrix}
\end{align} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\frac{\partial (w^T x)_2 }{\partial w} = \begin{pmatrix} 0 &amp; x_1 &amp; 0 &amp; \dots &amp; 0 \\ 0 &amp; x_2 &amp; 0 &amp; \dots &amp; 0 \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; x_m &amp; 0 &amp; \dots &amp; 0 \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vdots&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\frac{\partial (w^T x)_K }{\partial w} = \begin{pmatrix} 0 &amp; \dots &amp; 0 &amp; x_1 \\ 0 &amp; \dots &amp; 0 &amp; x_2 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \dots &amp; 0 &amp; x_m \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;showing-steps-in-vector-tensor-multiplication&quot;&gt;Showing steps in vector-tensor multiplication&lt;/h3&gt;

&lt;p&gt;This section pertains to showing details for the tensor multiplication step mentioned in &lt;a href=&quot;#softmax-regression-differentiation&quot;&gt;this section&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let $a$ be a vector of length $K$.  Then:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
a^T \left[\frac{\partial w^T x}{\partial w}\right] &amp;=  \begin{pmatrix} a_1 &amp; a_2 &amp; \dots &amp; a_K \end{pmatrix}\begin{pmatrix} 
\frac{\partial (w^T x)_1}{\partial w} \\ \frac{\partial (w^T x)_2}{\partial w} \\ \dots \\ \frac{\partial (w^T x)_K}{\partial w} 
\end{pmatrix} \\
&amp;= \sum_{j=1}^K a_j \frac{\partial (w^T x)_j }{\partial w} \\
&amp;= a_1 \begin{pmatrix} x_1 &amp; 0 &amp; \dots &amp; 0 \\ x_2 &amp; 0 &amp; \dots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_m &amp; 0 &amp; \dots &amp; 0 \end{pmatrix} + \dots + a_K \begin{pmatrix} 0 &amp; \dots &amp; 0 &amp; x_1 \\ 0 &amp; \dots &amp; 0 &amp; x_2 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \dots &amp; 0 &amp; x_m \end{pmatrix} \\
&amp;= \begin{pmatrix} a_1 x_1 &amp; a_2 x_1 &amp; \dots &amp; a_K x_1 \\ a_1 x_2 &amp; a_2 x_2 &amp; \dots &amp; a_K x_2 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ a_1 x_m &amp; a_2 x_m &amp; \dots &amp; a_K x_m \end{pmatrix} \\
&amp;= x a^T
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Technically, the result is a $1 \times m \times K$ tensor, but we can effectively drop the first dimension and just treat the result as an $m \times K$ matrix.&lt;/p&gt;

&lt;h3 id=&quot;derivatives-of-other-activation-functions&quot;&gt;Derivatives of other activation functions&lt;/h3&gt;

&lt;p&gt;While $\phi_L$ is usually the softmax function, we usually defer to other choices for $\phi_1,\dots,\phi_{L-1}$.&lt;/p&gt;

&lt;p&gt;For example, popular choices include element-wise application of&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$\phi(z) = \tanh(z) = \frac{1 - e^{-2z}}{1 + e^{-2z}}$ where $\phi’(z) = 1 - \tanh^2(z)$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\phi(z) = ReLU(z) = \max(0, z)$ where $\phi’(z) = \mathbf{1}_{z \gt 0}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then the derivative of the activation function $\phi_l$ characterized by $\phi$ is a diagonal matrix:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\frac{\partial \phi_l(z^{(l)})}{z^{(l)}} = \begin{pmatrix}  \phi&#39;(z_1^{(l)}) &amp; 0 &amp; \dots &amp; 0 \\ 0 &amp; \phi&#39;(z_2^{(l)}) &amp; \dots &amp; 0 \\ \vdots  &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \dots &amp; \phi&#39;(z_{m_l}^{(l)})  \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;faster-computation-of-delta-terms&quot;&gt;Faster computation of delta terms&lt;/h3&gt;

&lt;h4 id=&quot;softmax-output-layer-activation&quot;&gt;Softmax output layer activation&lt;/h4&gt;

&lt;p&gt;Since $\phi_L$ is likely the softmax function, we can use the result from softmax regression:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta^{(L)} = \left[h^{(L)} - y\right]^T&lt;/script&gt;

&lt;p&gt;as opposed to performing the full $\frac{\partial \mathcal{L}}{\partial h^{(L)}}  \frac{\partial h^{(L)}}{\partial z^{(L)}}$ multiplication.&lt;/p&gt;

&lt;h4 id=&quot;activation-functions-with-diagonal-jacobians&quot;&gt;Activation functions with diagonal Jacobians&lt;/h4&gt;

&lt;p&gt;On the other hand, $\phi_{L-1},\dots,\phi_1$ are usually chosen to be element-wise applications of $\phi$ (e.g. expit, $\tanh$, ReLU).  Unlike the softmax function, their derivatives are diagonal matrices:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\frac{\partial \phi_l(z)}{\partial z} = \begin{pmatrix} \phi&#39;(z_1) &amp; 0 &amp; 0 &amp; \dots &amp; 0 \\ 0 &amp; \phi&#39;(z_2) &amp; 0 &amp; \dots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; 0 &amp; \dots &amp; \phi&#39;(z_d) \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;Then in each iteration of backpropagation, the $\delta^{(l)} \to \delta^{(l-1)}$ update can be simplified to:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}\delta^{(l-1)} &amp;= \delta^{(l)} \frac{\partial z^{(l)}}{\partial h^{(l-1)}}  \frac{\partial h^{(l-1)}}{\partial z^{(l-1)}} \\
&amp;= \delta^{(l)} w_l^T \frac{\partial h^{(l-1)}}{\partial z^{(l-1)}} \\
&amp;= \begin{pmatrix}  \phi&#39;(z^{(l-1)}_1) \sum_j^{m_l} \delta_j^{(l)} w^{(l)}_{1j}  \\  \phi&#39;(z^{(l-1)}_2) \sum_j^{m_l} \delta_j^{(l)} w^{(l)}_{2j} \\ \vdots \\  \phi&#39;(z^{(l-1)}_{m_{l-1}}) \sum_j^{m_l} \delta_j^{(l)} w^{(l)}_{m_{l-1}j} \end{pmatrix}^T \\
&amp;= \left[ \delta^{(l)} w_l^T\right] \odot \left[\phi&#39;\left(z^{(l-1)}\right)\right]^T
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Thus, we can replace matrix multiplication of $\frac{\partial h^{(l-1)}}{\partial z^{(l-1)}}$ with the cheaper element-wise multiplication of $\left[\phi’\left(z^{(l-1)}\right)\right]^T$.&lt;/p&gt;

&lt;h1 id=&quot;miscellaneous&quot;&gt;Miscellaneous&lt;/h1&gt;

&lt;p&gt;Here’s a collection of topics that I felt were loosely relevant, but I didn’t know how to fit them into the post.&lt;/p&gt;

&lt;h3 id=&quot;bias&quot;&gt;Bias&lt;/h3&gt;

&lt;p&gt;We’ve failed to address inclusion of a bias term among the parameters.&lt;/p&gt;

&lt;p&gt;For logistic/softmax regression, this can be done by augmenting the inputs $\tilde{x} = [1, x]^T$.  The weight vector $w$ will include an additional element to ensure that the product $\tilde{z} = w^T \tilde{x}$ is computable.  The learned value is the bias.&lt;/p&gt;

&lt;p&gt;For neural networks, we can similarly augment the inputs $\tilde{h}^{(l)} = [1, h^{(l)}]^T$ for $l = 0, \dots, L-1$.  The weight matrices $w_1, \dots, w_L$ will each include an additional row to ensure the products $\tilde{z}_l = w_l^T \tilde{h}^{(l-1)}$  are computable for $l = 1,\dots,L$.&lt;/p&gt;

&lt;h3 id=&quot;quadratic-loss&quot;&gt;Quadratic loss&lt;/h3&gt;

&lt;p&gt;Our derivations have been for negative log-likelihood loss for classification.  For regression problems in which $y$’s can take value beyond ${1, 0}$, the quadratic loss is often used instead:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}(w_{1:L}) = \frac{1}{2} \sum_{i=1}^n \left( y_i - h_i^{(L)}\right)^T \left( y_i - h_i^{(L)}\right)&lt;/script&gt;

&lt;p&gt;The same chain rule pattern holds, but now the form of $\frac{\partial \mathcal{L}}{\partial h^{(L)}}$ is different:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \mathcal{L}}{\partial h^{(L)}} = \left(h^{(L)} - y \right)^T&lt;/script&gt;

&lt;p&gt;Everything else remains the same.&lt;/p&gt;

&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;

&lt;p&gt;Maximum likelihood tends to overfit and we often include a penalty term in the loss function to guard against this.  For example:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}(w_{1:L}) = \sum_{i=1}^n y^T \log h_i^{(L)} + \frac{\lambda}{2} \Vert  w \Vert_2^2&lt;/script&gt;

&lt;p&gt;where $\lambda &amp;gt; 0$ and $\Vert w \Vert_2^2$ denotes the sum of squared $w_{i,j}^{(l)}$ (except bias terms).&lt;/p&gt;

&lt;p&gt;Then:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \mathcal{L}(w_{1:L})}{\partial w_l} = \frac{\partial \sum_{i=1}^n y^T \log h_i^{(L)}}{\partial w_l} + \frac{\lambda}{2} \frac{\partial \Vert w \Vert_2^2}{\partial w_l}&lt;/script&gt;

&lt;p&gt;for which the former term we’ve already derived.  The latter term is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \Vert w \Vert_2^2}{\partial w_l} = 2 w_l&lt;/script&gt;

&lt;p&gt;which is an $m_{l-1} \times m_l$ matrix.&lt;/p&gt;

&lt;p&gt;Since regularization only contributes an additive term that doesn’t depend on anything else, the backpropagation algorithm remains unchanged.  We can simply add $\lambda w_l$ to the corresponding $\frac{\partial \mathcal{L}(w_{1:L})}{\partial w_l}$ values afterwards.&lt;/p&gt;

&lt;h3 id=&quot;training&quot;&gt;Training&lt;/h3&gt;

&lt;p&gt;Gradient-based optimization procedures begin with an initial guess $w^{(0)}$ and repeatedly perform an update step until convergence (i.e.$\vert w^{(t+1)} - w^{(t)}\vert \lt \epsilon$).&lt;/p&gt;

&lt;p&gt;Here, $w^{(t)}$ refers to the entire set of parameters at iteration $t$.  This can include all $w_1,\dots,w_L$ of a neural network.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Gradient descent update:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^{(t+1)} \gets w^{(t)} - \eta \frac{\partial \mathcal{L}(w^{(t)})}{\partial w^{(t)}}&lt;/script&gt;

&lt;p&gt;where $\eta \gt 0$ is the step size (aka learning rate) that is usually chosen to decrease per iteration.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;For logistic regression, we can use the faster Newton’s method update:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^{(t+1)} \gets w^{(t)} - H_{\mathcal{L}}^{-1}(w^{(t)}) \frac{\partial \mathcal{L}(w^{(t)})}{\partial w^{(t)}}&lt;/script&gt;

&lt;p&gt;where $H_{\mathcal{L}}^{-1}$ is the inverse of the Hessian of $\mathcal{L}(w)$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H_{\mathcal{L}}^{-1}(w^{(t)}) = \sum_{i=1}^n \phi(w^T x_i) \left(1 - \phi(w^Tx_i) \right) x_i x_i^T&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;For neural networks, gradient descent can get stuck in local optima since the loss function is no longer convex like it is for logistic regression.  Also, models with this many parameters typically require large training sets which may not fit in memory at once.&lt;/p&gt;

&lt;p&gt;A popular alternative is (minibatch) stochastic gradient descent which involves computing the gradient using some manageable $n_{batch} \lt\lt n$ subset of points.  The resulting approximate gradient is noisier which can help the algorithm avoid local optima.&lt;/p&gt;</content><author><name>Kyle Lo</name><email>kyleclo@uw.edu</email></author><summary>Here are some notes containing step-by-step derivations of the backpropagation algorithm for neural networks.  This post serves more as a reference than as an introduction to the subject.  It assumes the reader is already familiar with neural networks and is comfortable with differentiation and matrix algebra.</summary></entry><entry><title>Derivations for the forward-backward algorithm</title><link href="/forward-backward-algorithm/" rel="alternate" type="text/html" title="Derivations for the forward-backward algorithm" /><published>2016-09-21T00:00:00-07:00</published><updated>2016-09-21T00:00:00-07:00</updated><id>/forward-backward-algorithm</id><content type="html" xml:base="/forward-backward-algorithm/">&lt;p&gt;First post!  To test this out: Here are derivations for the forward-backward algorithm by &lt;a href=&quot;https://projecteuclid.org/euclid.aoms/1177697196&quot;&gt;Baum et. al. (1970)&lt;/a&gt; for computing posteriors of hidden states in HMMs.&lt;/p&gt;

&lt;h1 id=&quot;hidden-markov-model&quot;&gt;Hidden Markov model&lt;/h1&gt;

&lt;h3 id=&quot;specification&quot;&gt;Specification&lt;/h3&gt;
&lt;p&gt;Let there be a sequence ${x_1,\dots,x_n}$, where each $x_t$ denotes the system as being in a hidden state at time $t$.  The sequence is a discrete time Markov chain, so&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_t \vert x_1,\dots,x_{t-1}) = p(x_t \vert x_{t-1})&lt;/script&gt;

&lt;p&gt;There are $m$ hidden states, and $p(x_t = j \vert x_{t-1} = i)$ is the probability of transition from state $i$ to state $j$.&lt;/p&gt;

&lt;p&gt;While the states are hidden, we observe a sequence of output values ${y_1,\dots,y_n}$, where each $y_t$ is drawn from a distribution $p(y_t \vert x_t)$ that depends on the current hidden state $x_t$.  Note that $y_t$ can be discrete or continuous.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/8/83/Hmm_temporal_bayesian_net.svg&quot; alt=&quot;HMM&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(Image taken from Wikipedia)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For simplicity, we’ll assume these probabilities/distributions are the same across time.&lt;/p&gt;

&lt;!-- ### Example --&gt;
&lt;!-- Let $x_t \in \{\text{Sick}, \text{Healthy}\}$, and let $y_t$ be counts of the number of sneezes on day $t$.  --&gt;

&lt;!-- Suppose you recorded how many times you sneezed every day for a year (weirdo).  Can you tell which days you were sick from this data? --&gt;

&lt;h3 id=&quot;goal&quot;&gt;Goal&lt;/h3&gt;
&lt;p&gt;We want to compute the posterior probabilities over possible hidden states $p(x_t \vert y_1,\dots,y_n)$ at all time points $t = 1,\dots,n$.&lt;/p&gt;

&lt;h1 id=&quot;forward-backward-algorithm&quot;&gt;Forward-backward algorithm&lt;/h1&gt;

&lt;h3 id=&quot;given&quot;&gt;Given&lt;/h3&gt;

&lt;p&gt;Assume we know for $t = 1,\dots,n$:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;All transition probabilities $p(x_t \vert x_{t-1})$&lt;/li&gt;
  &lt;li&gt;All output probabilities $p(y_t \vert x_t)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and also the distribution for the initial state $p(x_1)$.&lt;/p&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;From the image above, we see that emissions are conditionally independent of past emissions given the current hidden state.  Hence, we can factor our target posterior:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} p(x_t \vert y_1,\dots,y_n) &amp;\propto p(x_t, y_1, \dots, y_n) \\ &amp;=  p(y_{t+1},\dots,y_n \vert x_t, y_1,\dots,y_t) p(x_t, y_1,\dots,y_t) \\ &amp;= \underbrace{p(y_{t+1},\dots,y_n \vert x_t)}_{\text{backward}} \underbrace{p(x_t, y_1,\dots,y_t)}_{\text{forward}}  \end{align} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;
&lt;p&gt;For each $t = 1,\dots,n$:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Use the forward algorithm to compute $p(x_1,y_1,\dots,y_t)$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use the backward algorithm to compute $p(y_{t+1},\dots,y_n \vert x_t)$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multiply the outcomes together to get $p(x_t \vert y_1,\dots,y_n)$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;forward-algorithm&quot;&gt;Forward algorithm&lt;/h1&gt;

&lt;h3 id=&quot;motivation-1&quot;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;Suppose we’re interested in the distribution of the observed output sequence $p(y_1\dots,y_n)$.&lt;/p&gt;

&lt;p&gt;A brute force method:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} p(y_1,\dots,y_n) &amp;= \sum_{\{x_1,\dots,x_n\} } p(x_1,\dots,x_n) p(y_1,\dots,y_n \vert x_1,\dots,x_n)  \\
&amp;= \sum_{\{x_1,\dots,x_n\} } p(x_1) \prod_{t=2}^n p(x_t \vert x_{t-1}) \prod_{t=1}^n p(y_t \vert x_t) \\
&amp;= \sum_{\{x_1,\dots,x_n\} } p(x_1) p(y_1 \vert x_t) \prod_{t=2}^n p(x_t \vert x_{t-1})  p(y_t \vert x_t) \end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;This takes $\mathcal{O}(nm^n)$ operations!&lt;/p&gt;

&lt;p&gt;Instead, here’s a $\mathcal{O}(nm^2)$ method that uses dynamic programming in the form of the forward algorithm:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y_1,\dots,y_n) = \sum_{x_n = 1}^m \underbrace{p(x_n, y_1,\dots,y_n)}_{\text{use forward algorithm}}&lt;/script&gt;

&lt;p&gt;Now we just need those summands.&lt;/p&gt;

&lt;h3 id=&quot;algorithm-1&quot;&gt;Algorithm&lt;/h3&gt;

&lt;p&gt;First compute:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_1,y_1) = p(y_1 \vert x_1)p(x_1)&lt;/script&gt;

&lt;p&gt;Then for each $t = 2,\dots,n$ compute:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align} p(x_t,y_1,\dots,y_t) &amp;= \sum_{x_{t-1} = 1}^m p(x_t,x_{t-1}, y_1,\dots,y_t) \\ 
&amp;= \sum_{x_{t-1} = 1}^m p(y_t \vert x_t,x_{t-1}, y_1,\dots,y_{t-1}) p(x_t \vert x_{t-1}, y_1,\dots,y_{t-1}) p(x_{t-1}, y_1,\dots,y_{t-1}) \\
&amp;= \underbrace{p(y_t \vert x_t)}_{\text{known}} \sum_{x_{t-1} = 1}^m  \underbrace{p(x_t \vert x_{t-1})}_{\text{known}} \underbrace{p(x_{t-1}, y_1,\dots,y_{t-1})}_{\text{forward algorithm result for }t-1} \\ \end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&quot;backward-algorithm&quot;&gt;Backward algorithm&lt;/h1&gt;

&lt;p&gt;We have the forward part needed to compute $p(x_t \vert y_1,\dots,y_n)$.  Now we need the backward part.&lt;/p&gt;

&lt;h3 id=&quot;algorithm-2&quot;&gt;Algorithm&lt;/h3&gt;

&lt;p&gt;For $t = n$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y_{n+1} \vert x_n) = 1&lt;/script&gt;

&lt;p&gt;Note that the notation is a formality since there is no observed $y_{n+1}$.&lt;/p&gt;

&lt;p&gt;Then for each $t = n-1,\dots,1$ compute:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}p(y_{t+1},\dots,y_n \vert x_t) &amp;= \sum_{x_{t+1} = 1}^m p(y_{t+1},\dots,y_n,x_{t+1} \vert x_t) \\
&amp;= \sum_{x_{t+1} = 1}^m p(y_{t+2}, \dots,y_n \vert y_{t+1}, x_t, x_{t+1}) p(y_{t+1},x_{t+1} \vert x_t) \\
&amp;= \sum_{x_{t+1} = 1}^m p(y_{t+2}, \dots,y_n \vert y_{t+1}, x_t, x_{t+1}) p(y_{t+1} \vert  x_t, x_{t+1}) p(x_{t+1} \vert x_t)\\
&amp;= \sum_{x_{t+1} = 1}^m  \underbrace{p(y_{t+2}, \dots,y_n \vert  x_{t+1})}_{\text{backward algorithm result for }t+1} \underbrace{p(y_{t+1} \vert  x_{t+1})}_{\text{known}} \underbrace{p(x_{t+1} \vert x_t)}_{\text{known}}  \\ \end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Now we have all the pieces to compute $p(x_t \vert y_1,\dots,y_n)$.  We can use this to find the most likely state at any time $t$.&lt;/p&gt;

&lt;p&gt;Of course, this isn’t enough by itself:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The Viterbi algorithm finds the most likely sequence of hidden states (i.e. ${x_1,\dots,x_n}$ such that $p(x_1,\dots,x_n \vert y_1,\dots,y_n)$ is maximized ).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Baum-Welch algorithm uses the forward-backward algorithm to compute maximum likelihood estimates of the HMM parameters (i.e. the probabilities/distributions that we took as “given”).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of this introductory material on HMMs can be found in Sections I-III of:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), 257-286.&lt;/em&gt;&lt;/p&gt;</content><author><name>Kyle Lo</name><email>kyleclo@uw.edu</email></author><summary>First post!  To test this out: Here are derivations for the forward-backward algorithm by Baum et. al. (1970) for computing posteriors of hidden states in HMMs.</summary></entry></feed>
