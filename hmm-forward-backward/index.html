
<p>These are simple derivations of the famous forward-backward algorithm by <a href="https://projecteuclid.org/euclid.aoms/1177697196">Baum et. al. (1970)</a> for computing posteriors of hidden states in HMMs.</p>

<h1 id="hidden-markov-model">Hidden Markov model</h1>

<h3 id="specification">Specification</h3>
<p>Let there be a sequence ${x_1,\dots,x_n}$, where each $x_t$ denotes the system as being in a hidden state at time $t$.  The sequence is a discrete time Markov chain, so</p>

<script type="math/tex; mode=display">p(x_t|x_1,\dots,x_{t-1}) = p(x_t|x_{t-1})</script>

<table>
  <tbody>
    <tr>
      <td>There are $m$ hidden states, and $p(x_t = j</td>
      <td>x_{t-1} = i)$ is the probability of transition from state $i$ to state $j$.</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>While the states are hidden, we observe a sequence of output values ${y_1,\dots,y_n}$, where each $y_t$ is drawn from a distribution $p(y_t</td>
      <td>x_t)$ that depends on the current hidden state $x_t$.  Note that $y_t$ can be discrete or continuous.</td>
    </tr>
  </tbody>
</table>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Hmm_temporal_bayesian_net.svg" alt="HMM" /></p>

<p><em>(Image taken from Wikipedia)</em></p>

<p>For simplicity, we’ll assume these probabilities/distributions are the same across time.</p>

<!-- ### Example -->
<!-- Let $x_t \in \{\text{Sick}, \text{Healthy}\}$, and let $y_t$ be counts of the number of sneezes on day $t$.  -->

<!-- Suppose you recorded how many times you sneezed every day for a year (weirdo).  Can you tell which days you were sick from this data? -->

<h3 id="goal">Goal</h3>
<p>We want to compute the posterior probabilities over possible hidden states $p(x_t|y_1,\dots,y_n)$ at all time points $t = 1,\dots,n$.</p>

<h1 id="forward-backward-algorithm">Forward-backward algorithm</h1>

<h3 id="given">Given</h3>

<p>Assume we know for $t = 1,\dots,n$:</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>All transition probabilities $p(x_t</td>
          <td>x_{t-1})$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>All output probabilities $p(y_t</td>
          <td>x_t)$</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p>and also the distribution for the initial state $p(x_1)$.</p>

<!-- Think of these as the HMM model parameters (which we'll need to tune later).  -->

<h3 id="motivation">Motivation</h3>

<p>From the image above, we see that emissions are conditionally independent of past emissions given the current hidden state.  Hence, we can factor our target posterior:
<script type="math/tex">% <![CDATA[
\begin{align} p(x_t|y_1,\dots,y_n) &\propto p(x_t, y_1, \dots, y_n) \\ &=  p(y_{t+1},\dots,y_n|x_t, y_1,\dots,y_t) p(x_t, y_1,\dots,y_t) \\ &= \underbrace{p(y_{t+1},\dots,y_n|x_t)}_{\text{backward}} \underbrace{p(x_t, y_1,\dots,y_t)}_{\text{forward}}  \end{align} %]]></script></p>

<h3 id="algorithm">Algorithm</h3>
<p>For each $t = 1,\dots,n$:</p>

<ol>
  <li>
    <p>Use the forward algorithm to compute $p(x_1,y_1,\dots,y_t)$</p>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Use the backward algorithm to compute $p(y_{t+1},\dots,y_n</td>
          <td>x_t)$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Multiply the outcomes together to get $p(x_t</td>
          <td>y_1,\dots,y_n)$</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<h1 id="forward-algorithm">Forward algorithm</h1>

<h3 id="motivation-1">Motivation</h3>
<p>Suppose we’re interested in the distribution of the observed output sequence $p(y_1\dots,y_n)$.</p>

<p>A brute force method:
<script type="math/tex">% <![CDATA[
\begin{align} p(y_1,\dots,y_n) &= \sum_{\{x_1,\dots,x_n\} } p(x_1,\dots,x_n) p(y_1,\dots,y_n|x_1,\dots,x_n)  \\
&= \sum_{\{x_1,\dots,x_n\} } p(x_1) \prod_{t=2}^n p(x_t|x_{t-1}) \prod_{t=1}^n p(y_t|x_t) \\
&= \sum_{\{x_1,\dots,x_n\} } p(x_1) p(y_1|x_t) \prod_{t=2}^n p(x_t|x_{t-1})  p(y_t|x_t) \end{align} %]]></script></p>

<p>This takes $\mathcal{O}(nm^n)$ operations!</p>

<p>Instead, here’s a $\mathcal{O}(nm^2)$ method that uses dynamic programming in the form of the forward algorithm:</p>

<script type="math/tex; mode=display">p(y_1,\dots,y_n) = \sum_{x_n = 1}^m \underbrace{p(x_n, y_1,\dots,y_n)}_{\text{use forward algorithm}}</script>

<p>Now we just need those summands.</p>

<h3 id="algorithm-1">Algorithm</h3>

<p>First compute:
<script type="math/tex">p(x_1,y_1) = p(y_1|x_1)p(x_1)</script></p>

<p>Then for each $t = 2,\dots,n$ compute:
<script type="math/tex">% <![CDATA[
\begin{align} p(x_t,y_1,\dots,y_t) &= \sum_{x_{t-1} = 1}^m p(x_t,x_{t-1}, y_1,\dots,y_t) \\ 
&= \sum_{x_{t-1} = 1}^m p(y_t|x_t,x_{t-1}, y_1,\dots,y_{t-1}) p(x_t|x_{t-1}, y_1,\dots,y_{t-1}) p(x_{t-1}, y_1,\dots,y_{t-1}) \\
&= \underbrace{p(y_t|x_t)}_{\text{known}} \sum_{x_{t-1} = 1}^m  \underbrace{p(x_t|x_{t-1})}_{\text{known}} \underbrace{p(x_{t-1}, y_1,\dots,y_{t-1})}_{\text{forward algorithm result for $t-1$}} \\ \end{align} %]]></script></p>

<h1 id="backward-algorithm">Backward algorithm</h1>

<table>
  <tbody>
    <tr>
      <td>We have the forward part needed to compute $p(x_t</td>
      <td>y_1,\dots,y_n)$.  Now we need the backward part.</td>
    </tr>
  </tbody>
</table>

<h3 id="algorithm-2">Algorithm</h3>

<p>For $t = n$:
<script type="math/tex">p(y_{n+1}|x_n) = 1</script>
Note that the notation is a formality since there is no observed $y_{n+1}$.</p>

<p>Then for each $t = n-1,\dots,1$ compute:
<script type="math/tex">% <![CDATA[
\begin{align}p(y_{t+1},\dots,y_n|x_t) &= \sum_{x_{t+1} = 1}^m p(y_{t+1},\dots,y_n,x_{t+1}|x_t) \\
&= \sum_{x_{t+1} = 1}^m p(y_{t+2}, \dots,y_n|y_{t+1}, x_t, x_{t+1}) p(y_{t+1},x_{t+1}|x_t) \\
&= \sum_{x_{t+1} = 1}^m p(y_{t+2}, \dots,y_n|y_{t+1}, x_t, x_{t+1}) p(y_{t+1}| x_t, x_{t+1}) p(x_{t+1}|x_t)\\
&= \sum_{x_{t+1} = 1}^m  \underbrace{p(y_{t+2}, \dots,y_n| x_{t+1})}_{\text{backward algorithm result for $t+1$}} \underbrace{p(y_{t+1}| x_{t+1})}_{\text{known}} \underbrace{p(x_{t+1}|x_t)}_{\text{known}}  \\ \end{align} %]]></script></p>

<h1 id="conclusion">Conclusion</h1>

<table>
  <tbody>
    <tr>
      <td>Now we have all the pieces to compute $p(x_t</td>
      <td>y_1,\dots,y_n)$.  We can use this to find the most likely state at any time $t$.</td>
    </tr>
  </tbody>
</table>

<p>Of course, this isn’t enough by itself:</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>The Viterbi algorithm finds the most likely sequence of hidden states (i.e. ${x_1,\dots,x_n}$ such that $p(x_1,\dots,x_n</td>
          <td>y_1,\dots,y_n)$ is maximized ).</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>The Baum-Welch algorithm uses the forward-backward algorithm to compute maximum likelihood estimates of the HMM parameters (i.e. the probabilities/distributions that we took as “given”).</li>
</ul>

<h1 id="postface">Postface</h1>

<p>Had to learn stuff about HMMs while working on changepoint problems, and I figured I might as well organize some notes for future reference.  Hopefully someone else also finds these derivations useful.</p>

<p>Credit given to Jeffrey Miller’s <a href="https://www.youtube.com/user/mathematicalmonk">mini-lectures</a>, which were really easy to digest for someone new to the material like myself.</p>

<p>For an introduction to HMMs, I recommend reading Sections I-III of:
<em>Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), 257-286.</em></p>
