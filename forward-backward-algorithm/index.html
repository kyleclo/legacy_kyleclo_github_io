<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Derivations for the forward-backward algorithm &middot; Kyle Lo
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/icons/apple-icon-precomposed.png">
  <link rel="shortcut icon" href="/images/icons/favicon.ico">

  <!-- Mathjax -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
  </script>  

  <script type="text/javascript"
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
  </script>

  <!-- Google Analytics -->
  <!-- see https://github.com/gastonstat/gastonstat.github.io/blob/master/_includes/head.html -->

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-image">
      <img src="/images/bio.jpg" alt="Kyle Lo">
    </div>
    <div class="sidebar-about">
    <h1>
        <a href="/">
          Kyle Lo
        </a>
    </h1>  
    <p class="lead">Statistics and stuff</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
      
        
          
        
      
        
      

      <a class="sidebar-nav-item" href="https://github.com/solstat/snake_learning">deep-rf</a>
    </nav>

    <p>&copy; 2016. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Derivations for the forward-backward algorithm</h1>
  <span class="post-date">21 Sep 2016</span>
  <p>These are simple derivations for the famous forward-backward algorithm by <a href="https://projecteuclid.org/euclid.aoms/1177697196">Baum et. al. (1970)</a> for computing posteriors of hidden states in HMMs.</p>

<h1 id="hidden-markov-model">Hidden Markov model</h1>

<h3 id="specification">Specification</h3>
<p>Let there be a sequence ${x_1,\dots,x_n}$, where each $x_t$ denotes the system as being in a hidden state at time $t$.  The sequence is a discrete time Markov chain, so</p>

<script type="math/tex; mode=display">p(x_t \vert x_1,\dots,x_{t-1}) = p(x_t \vert x_{t-1})</script>

<p>There are $m$ hidden states, and $p(x_t = j \vert x_{t-1} = i)$ is the probability of transition from state $i$ to state $j$.</p>

<p>While the states are hidden, we observe a sequence of output values ${y_1,\dots,y_n}$, where each $y_t$ is drawn from a distribution $p(y_t \vert x_t)$ that depends on the current hidden state $x_t$.  Note that $y_t$ can be discrete or continuous.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Hmm_temporal_bayesian_net.svg" alt="HMM" /></p>

<p><em>(Image taken from Wikipedia)</em></p>

<p>For simplicity, we’ll assume these probabilities/distributions are the same across time.</p>

<!-- ### Example -->
<!-- Let $x_t \in \{\text{Sick}, \text{Healthy}\}$, and let $y_t$ be counts of the number of sneezes on day $t$.  -->

<!-- Suppose you recorded how many times you sneezed every day for a year (weirdo).  Can you tell which days you were sick from this data? -->

<h3 id="goal">Goal</h3>
<p>We want to compute the posterior probabilities over possible hidden states $p(x_t \vert y_1,\dots,y_n)$ at all time points $t = 1,\dots,n$.</p>

<h1 id="forward-backward-algorithm">Forward-backward algorithm</h1>

<h3 id="given">Given</h3>

<p>Assume we know for $t = 1,\dots,n$:</p>

<ul>
  <li>All transition probabilities $p(x_t \vert x_{t-1})$</li>
  <li>All output probabilities $p(y_t \vert x_t)$</li>
</ul>

<p>and also the distribution for the initial state $p(x_1)$.</p>

<h3 id="motivation">Motivation</h3>

<p>From the image above, we see that emissions are conditionally independent of past emissions given the current hidden state.  Hence, we can factor our target posterior:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} p(x_t \vert y_1,\dots,y_n) &\propto p(x_t, y_1, \dots, y_n) \\ &=  p(y_{t+1},\dots,y_n \vert x_t, y_1,\dots,y_t) p(x_t, y_1,\dots,y_t) \\ &= \underbrace{p(y_{t+1},\dots,y_n \vert x_t)}_{\text{backward}} \underbrace{p(x_t, y_1,\dots,y_t)}_{\text{forward}}  \end{align} %]]></script>

<h3 id="algorithm">Algorithm</h3>
<p>For each $t = 1,\dots,n$:</p>

<ol>
  <li>
    <p>Use the forward algorithm to compute $p(x_1,y_1,\dots,y_t)$</p>
  </li>
  <li>
    <p>Use the backward algorithm to compute $p(y_{t+1},\dots,y_n \vert x_t)$</p>
  </li>
  <li>
    <p>Multiply the outcomes together to get $p(x_t \vert y_1,\dots,y_n)$</p>
  </li>
</ol>

<h1 id="forward-algorithm">Forward algorithm</h1>

<h3 id="motivation-1">Motivation</h3>
<p>Suppose we’re interested in the distribution of the observed output sequence $p(y_1\dots,y_n)$.</p>

<p>A brute force method:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} p(y_1,\dots,y_n) &= \sum_{\{x_1,\dots,x_n\} } p(x_1,\dots,x_n) p(y_1,\dots,y_n \vert x_1,\dots,x_n)  \\
&= \sum_{\{x_1,\dots,x_n\} } p(x_1) \prod_{t=2}^n p(x_t \vert x_{t-1}) \prod_{t=1}^n p(y_t \vert x_t) \\
&= \sum_{\{x_1,\dots,x_n\} } p(x_1) p(y_1 \vert x_t) \prod_{t=2}^n p(x_t \vert x_{t-1})  p(y_t \vert x_t) \end{align} %]]></script>

<p>This takes $\mathcal{O}(nm^n)$ operations!</p>

<p>Instead, here’s a $\mathcal{O}(nm^2)$ method that uses dynamic programming in the form of the forward algorithm:</p>

<script type="math/tex; mode=display">p(y_1,\dots,y_n) = \sum_{x_n = 1}^m \underbrace{p(x_n, y_1,\dots,y_n)}_{\text{use forward algorithm}}</script>

<p>Now we just need those summands.</p>

<h3 id="algorithm-1">Algorithm</h3>

<p>First compute:</p>

<script type="math/tex; mode=display">p(x_1,y_1) = p(y_1 \vert x_1)p(x_1)</script>

<p>Then for each $t = 2,\dots,n$ compute:
<script type="math/tex">% <![CDATA[
\begin{align} p(x_t,y_1,\dots,y_t) &= \sum_{x_{t-1} = 1}^m p(x_t,x_{t-1}, y_1,\dots,y_t) \\ 
&= \sum_{x_{t-1} = 1}^m p(y_t \vert x_t,x_{t-1}, y_1,\dots,y_{t-1}) p(x_t \vert x_{t-1}, y_1,\dots,y_{t-1}) p(x_{t-1}, y_1,\dots,y_{t-1}) \\
&= \underbrace{p(y_t \vert x_t)}_{\text{known}} \sum_{x_{t-1} = 1}^m  \underbrace{p(x_t \vert x_{t-1})}_{\text{known}} \underbrace{p(x_{t-1}, y_1,\dots,y_{t-1})}_{\text{forward algorithm result for }t-1} \\ \end{align} %]]></script></p>

<h1 id="backward-algorithm">Backward algorithm</h1>

<p>We have the forward part needed to compute $p(x_t \vert y_1,\dots,y_n)$.  Now we need the backward part.</p>

<h3 id="algorithm-2">Algorithm</h3>

<p>For $t = n$:</p>

<script type="math/tex; mode=display">p(y_{n+1} \vert x_n) = 1</script>

<p>Note that the notation is a formality since there is no observed $y_{n+1}$.</p>

<p>Then for each $t = n-1,\dots,1$ compute:
<script type="math/tex">% <![CDATA[
\begin{align}p(y_{t+1},\dots,y_n \vert x_t) &= \sum_{x_{t+1} = 1}^m p(y_{t+1},\dots,y_n,x_{t+1} \vert x_t) \\
&= \sum_{x_{t+1} = 1}^m p(y_{t+2}, \dots,y_n \vert y_{t+1}, x_t, x_{t+1}) p(y_{t+1},x_{t+1} \vert x_t) \\
&= \sum_{x_{t+1} = 1}^m p(y_{t+2}, \dots,y_n \vert y_{t+1}, x_t, x_{t+1}) p(y_{t+1} \vert  x_t, x_{t+1}) p(x_{t+1} \vert x_t)\\
&= \sum_{x_{t+1} = 1}^m  \underbrace{p(y_{t+2}, \dots,y_n \vert  x_{t+1})}_{\text{backward algorithm result for }t+1} \underbrace{p(y_{t+1} \vert  x_{t+1})}_{\text{known}} \underbrace{p(x_{t+1} \vert x_t)}_{\text{known}}  \\ \end{align} %]]></script></p>

<h1 id="conclusion">Conclusion</h1>

<p>Now we have all the pieces to compute $p(x_t \vert y_1,\dots,y_n)$.  We can use this to find the most likely state at any time $t$.</p>

<p>Of course, this isn’t enough by itself:</p>

<ul>
  <li>
    <p>The Viterbi algorithm finds the most likely sequence of hidden states (i.e. ${x_1,\dots,x_n}$ such that $p(x_1,\dots,x_n \vert y_1,\dots,y_n)$ is maximized ).</p>
  </li>
  <li>
    <p>The Baum-Welch algorithm uses the forward-backward algorithm to compute maximum likelihood estimates of the HMM parameters (i.e. the probabilities/distributions that we took as “given”).</p>
  </li>
</ul>

<h1 id="postface">Postface</h1>

<p>Had to learn stuff about HMMs while working on changepoint problems, and I figured I might as well organize some notes for future reference.  Hopefully someone else also finds these derivations useful.</p>

<p>Credit given to Jeffrey Miller’s <a href="https://www.youtube.com/user/mathematicalmonk">mini-lectures</a>, which were really easy to digest for someone new to the material like myself.</p>

<p>For an introduction to HMMs, I recommend reading Sections I-III of:</p>

<p><em>Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), 257-286.</em></p>

</div>


<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/deriving-the-backpropagation-algorithm/">
            Deriving the backpropagation algorithm
            <small>28 Dec 2016</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>

    </div>

  </body>
</html>
